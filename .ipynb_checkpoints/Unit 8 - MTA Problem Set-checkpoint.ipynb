{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.Save the Saturday, June 17th, 2017 data to a csv file. You can find it here: http://web.mta.info/developers/turnstile.html and read it in using read_csv. View the head of the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "EmptyDataError",
     "evalue": "No columns to parse from file",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mEmptyDataError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-f00614840562>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mMTA\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'MTA_data.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, skip_footer, doublequote, delim_whitespace, as_recarray, compact_ints, use_unsigned, low_memory, buffer_lines, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    653\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    654\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 655\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    656\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    657\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    403\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    404\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 405\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    406\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    407\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    760\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    761\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 762\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    763\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    764\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m    964\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'c'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    965\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'c'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 966\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    967\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    968\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'python'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1580\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'allow_leading_cols'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex_col\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1582\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1583\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1584\u001b[0m         \u001b[0;31m# XXX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__ (pandas/_libs/parsers.c:6260)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mEmptyDataError\u001b[0m: No columns to parse from file"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "MTA = pd.read_csv('MTA_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.View the dataframe columns. Is there extra whitespace at the end of any of the column names? Strip all of the whitespace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "MTA.columns = MTA.columns.str.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.In one line, determine how many rows are in your dataframe and if there are are any null entries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "MTA.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.In one line, print out the unique STATION names. How many are there? (Hint: use set)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(MTA.STATION)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(set(MTA.STATION)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5.Okay, so we understand what station represents. But what the heck are C/A, UNIT, and SCP? Keep in mind that in the larger stations, you might have multiple areas within one station that look like this:\n",
    "\n",
    "<img src=\"image.jpg\" style=\"width: 300px;\"/>\n",
    "\n",
    "Further complicating things, there are a few station names like 14TH ST that refer to more than one station location along that street.\n",
    "\n",
    "This data set is not very well documented. Welcome to the joys of real world data science!!!\n",
    "\n",
    "Read the following two links carefully to see other people's confusion and what information they have been able to gather:\n",
    "\n",
    "https://groups.google.com/forum/#!topic/mtadeveloperresources/AMVx2WUY9iI\n",
    "\n",
    "https://groups.google.com/forum/#!searchin/mtadeveloperresources/%22remote$20unit%22%7Csort:relevance/mtadeveloperresources/z8l3ZU9cY6Y/OFlHGkFAimQJ\n",
    "\n",
    "What did Patrick O'Hara and Katie Toth have to say?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Katie: Every time a person walks in the data says \"REGULAR\".  \"LOGON\" and \"DOORCLOSE\"\n",
    "Patrick: There are multiple names for one station (some names are dated)-there might be two names for one station"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6.To simplify our calculations right now, let's only look at ridership on Monday, June 12th, 2017. In one line, create a dataset called monday that just includes the dates listed as 06/12/2017.\n",
    "\n",
    "Then, use the command \"monday = monday.reset_index(drop=True)\" to reset the index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "monday = MTA[MTA.DATE == '06/12/2017']\n",
    "monday = monday.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7.Create a dictionary called monday_dict mapping the tuple (C/A, UNIT,SCP, STATION) to a list of tuples containing (TIME,EXITS).\n",
    "\n",
    "For example, the key ('A002', 'R051', '02-00-00','59 ST') in your dictionary should give the value:\n",
    "\n",
    "[('00:00:00', 2104727),\n",
    " ('04:00:00', 2104729),\n",
    " ('08:00:00', 2104813),\n",
    " ('12:00:00', 2105024),\n",
    " ('16:00:00', 2105081),\n",
    " ('20:00:00', 2105134)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "monday_dict={}\n",
    "for i in range(len(monday.index)):\n",
    "    mytuple=(monday['C/A'][i],monday['UNIT'][i],monday['SCP'][i],monday['STATION'][i])\n",
    "    if mytuple not in monday_dict:\n",
    "        monday_dict[mytuple]=[(monday['TIME'][i],monday['EXITS'][i])]\n",
    "    else:\n",
    "        monday_dict[mytuple].append((monday['TIME'][i],monday['EXITS'][i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8.Note: as you get more comfortable with pandas, you will rely more on built-in pandas capabilities and less on creating dictionaries from scratch. For example, run the following lines of code to verify that this dataframe gives you the same info that you got in Exercise 7."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x=monday.groupby(['C/A', 'UNIT', 'SCP', 'STATION']).groups #the keys are the station pairs and the values are the row indices\n",
    "flds = ['TIME','EXITS'] #we want to make values out of the remaining columns\n",
    "monday_exits = {key: monday.loc[val,flds] for key, val in x.items()}\n",
    "monday_exits[('A002', 'R051', '02-00-00','59 ST')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9.What the heck do these exit numbers represent? We can assume that they represent some sort of counter on the turnstile. We can subtract the exits at t=20 minus t=0 to figure out how many riders exited this turnstile between midnight and 8 pm.\n",
    "\n",
    "Can we calculate 20 - 0 for all of the stations? No! Unfortunately, the time increments aren't standardized. Many of the times are listed in 4 hour intervals of midnight, 4 am, 8 am, etc but not all. Make a frequency chart of the times for the monday dataframe from Exercise 6.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "monday.TIME.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10.Use your monday_dict from Exercise 7 to create a dictionary called monday_dict_diff that maps (C/A, UNIT, SCP, STATION) to the differences in exits between two consective times in order to see how many people exited through a turnstile within a given time interval.\n",
    "\n",
    "For example, the key ('A002', 'R051', '02-00-00','59 ST') should map to:\n",
    "\n",
    "[('04:00:00', 2),\n",
    " ('08:00:00', 84),\n",
    " ('12:00:00', 211),\n",
    " ('16:00:00', 57),\n",
    " ('20:00:00', 53)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "monday_dict_diff = {}\n",
    "\n",
    "for key,value in monday_dict.items():\n",
    "    for i in range(1,len(value)):\n",
    "        if key not in monday_dict_diff:\n",
    "            monday_dict_diff[key] = [(value[i][0],value[i][1]-value[i-1][1])]\n",
    "        else:\n",
    "            monday_dict_diff[key].append((value[i][0],value[i][1]-value[i-1][1]))\n",
    "print(monday_dict_diff[('A002', 'R051', '02-00-00','59 ST')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "11.Once again, note that pandas can do the above calculation for you. If you used the monday_exits dataframe from Exercise 8, run the following code to verify that you obtain what you just got in Exercise 10. It may take a bit longer to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "monday_diff = {}\n",
    "\n",
    "for turnstile, slice_df in monday_exits.items():\n",
    "    diff = slice_df['EXITS'].diff().values #calculates the exit difference between each entry\n",
    "    monday_diff[turnstile] = pd.Series(diff, index=slice_df['TIME'].values) #maps turnstile to (time, exit difference) pairs\n",
    "    for i,(key, val) in enumerate(monday_diff[turnstile].items()):\n",
    "        try: #need a try because you'll get an error for NAN difference values since there is one less difference than the number of times\n",
    "            monday_exits[turnstile].at[i,'EXITS'] = val\n",
    "        except:\n",
    "            continue\n",
    "    monday_exits[turnstile] = monday_exits[turnstile].drop(0)    #drop the first time because you only calculate differences after the second time.                   \n",
    "    \n",
    "monday_exits[('A002', 'R051', '02-00-00', '59 ST')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "12.Find how many people in total passed through a given turnstile between the hours given for 06/12/2017. For example, if a turnstile is on increments of 0,4,8,...,20, then you want to find out how many total people passed through between midnight and 8 pm. Create a dictionary called total_turnstile that maps (C/A,UNIT,SCP,STATION) to total Monday ridership. Use your dictionary from Exercise 10.\n",
    "\n",
    "Hint: the key ('A002', 'R051', '02-00-00', '59 ST') should map to 407 total riders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "monday_diff = {}\n",
    "\n",
    "for turnstile, slice_df in monday_exits.items():\n",
    "    total_turnstile = {}\n",
    "for key, value in monday_dict_diff.items():\n",
    "    for i in range(0, len(value)):\n",
    "        total_turnstile[key]=total_turnstile.get(key, 0)+value[i][1]\n",
    "\n",
    "print(total_turnstile[('A002', 'R051', '02-00-00', '59 ST')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "13.Use your work in Exercise 12 to create a dictionary called total_riders that maps the (C/A, UNIT, STATION) location to all riders that passed through ALL of the turnstiles in that area on Monday.\n",
    "\n",
    "Hint 1: use the get command\n",
    "\n",
    "Hint 2: ('A002', 'R051', '59 ST') should have 6704 total riders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#insert 13\n",
    "#for reference: \n",
    "#C/A = Control Area (A002)\n",
    "#UNIT = Remote Unit for a station (R051)\n",
    "#SCP = Subunit Channel Position represents an specific address for a device (02-00-00)\n",
    "\n",
    "total_riders = {}\n",
    "for key, value in total_turnstile.items():\n",
    "    new_key = (key[0], key[1], key[3])\n",
    "    total_riders[new_key]=total_riders.get(new_key, 0)+value\n",
    "print(total_riders[ ('A002', 'R051', '59 ST')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "14.Create a list of tuples called tuple_list using your total_riders dictionary so that you can sort the list in decending order to see busiest stations. Hint: the busiest area should be the PATH World Trade Center station."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuple_list=[]\n",
    "for key, value in total_riders.items():\n",
    "    mytuple=(value, key[2])\n",
    "    tuple_list.append(mytuple)\n",
    "tuple_list.sort(reverse=True)\n",
    "print(tuple_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "15.Look at the three smallest riderships in your above tuple list. Do they make sense? What about your data caused negative numbers? Welcome to the world of buggy real world data! Remove these three items from your tuple list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tuple_list[-1], tuple_list[-2], tuple_list[-3], tuple_list[-4])\n",
    "#They do not make sense, they are negative. Because data is weird. \n",
    "del tuple_list[-1]\n",
    "del tuple_list[-1]\n",
    "del tuple_list[-1]\n",
    "print(tuple_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "16.Create a barchart for the number of riders. You don't need to keep track of the names of each station, as that would get really messy to plot. Instead, you can just use a list comprehension to save the rider numbers to the y-values and give the stations the numbers 0,1,2,3,... for the x-values. You can use the following piece of code. Remember to add in axis labels and a title.\n",
    "\n",
    "x = range(len(tuple_list))\n",
    "\n",
    "y = [tuple_list[i][0] for i in range(len(tuple_list))]\n",
    "\n",
    "plt.bar(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "x = range(len(tuple_list))\n",
    "y = [tuple_list[i][0] for i in range(len(tuple_list))]\n",
    "plt.bar(x,y)\n",
    "plt.xlabel(\"Station Number\")\n",
    "plt.ylabel(\"Number of Riders\")\n",
    "plt.title(\"Ridership by Station\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "17.Perhaps we don't care about total ridership in a 24 period. Perhaps we only care about the morning commute. Let's assume that the majority of people arrive at their work location subway exit between 8 and 9 am.  \n",
    "\n",
    "Go back up to your frequency chart in Exercise 9. Note that the most common morning commutes would be gained from subtracting 9 am - 5 am and 10 am - 6 am and 11 am - 7 am and 12pm - 8am, for the stations that are broken down by those specific four hour intervals.\n",
    "\n",
    "As a dirty way to consider only the stations that are on these time intervals, save just the rows in your original monday dataframe that contain the TIME strings '05:00:00', '06:00:00',..., '12:00:00'. Remember you can do this by using OR statements using the \"|\" symbol and remembering parenthesis. Call this new dataframe \"morning\". Be sure to reset its index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "morning=monday[(monday.TIME ==\"05:00:00\")|(monday.TIME == \"06:00:00\")|(monday.TIME ==\"07:00:00\")|(monday.TIME == \"08:00:00\")|(monday.TIME == \"09:00:00\")|(monday.TIME == \"10:00:00\")|(monday.TIME == \"11:00:00\")|(monday.TIME == \"12:00:00\")]\n",
    "morning = morning.reset_index(drop=True)\n",
    "morning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "18.Now create a morning_dict by repeating your work in Exercise 7 on this morning dataframe. The dictionary should map the tuple (C/A, UNIT, SCP,STATION) to an inner dictionary containing {TIME: EXITS} for all Monday rides.\n",
    "\n",
    "Hint: ('A002', 'R051', '02-00-00','59 ST') should map to {'08:00:00': 2104813, '12:00:00': 2105024}."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "morning_dict={}\n",
    "for i in range(len(morning.index)):\n",
    "    mytuple= (morning['C/A'][i], morning.UNIT[i], morning.SCP[i], morning.STATION[i])\n",
    "    if mytuple not in morning_dict.keys():\n",
    "        morning_dict[mytuple]={morning.TIME[i]:morning.EXITS[i]}\n",
    "    else:\n",
    "        morning_dict[mytuple][morning.TIME[i]]=morning.EXITS[i]\n",
    "morning_dict[('A002', 'R051', '02-00-00','59 ST')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "19.We're almost ready to subtract the two consecutive times for each station to get the morning commutes. That is, if there are exactly two times for each station. Find which stations keys in your dictionary above do not contain exactly two times and delete them from the morning dictionary.\n",
    "\n",
    "How many keys are left in your morning_dict? There should be 4293."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bad_key = []\n",
    "for key, value in morning_dict.items():\n",
    "    if len(value) != 2:\n",
    "        bad_key.append(key)\n",
    "for key in bad_key:\n",
    "    if key in morning_dict:\n",
    "        del morning_dict[key]\n",
    "print(len(morning_dict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "20.Create a dictionary called morning_differences where (C/A, UNIT, STATION) maps to an inner dictionary containing {SCP: Morning Exit Differences}.\n",
    "\n",
    "For example, ('A002', 'R051', '59 ST') should map to:\n",
    "\n",
    "{'02-00-00': 211,\n",
    " '02-00-01': 128,\n",
    " '02-03-00': 654,\n",
    " '02-03-01': 630,\n",
    " '02-03-02': 533,\n",
    " '02-03-03': 401,\n",
    " '02-03-04': 186,\n",
    " '02-03-05': 49,\n",
    " '02-03-06': 8,\n",
    " '02-05-00': 0,\n",
    " '02-05-01': 0,\n",
    " '02-06-00': 4}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "morning_differences = {}\n",
    "for turnstile,times in morning_dict.items():\n",
    "    mytuple = (turnstile[0], turnstile[1], turnstile[3])\n",
    "    count = 0\n",
    "    for time, exit in times.items():\n",
    "        count = exit - count\n",
    "    if mytuple not in morning_differences:\n",
    "        morning_differences[mytuple]={turnstile[2]:count}\n",
    "    else:\n",
    "        morning_differences[mytuple][turnstile[2]]=count\n",
    "print(morning_differences[('A002', 'R051', '59 ST') ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "21.Create a dictionary called total_morning_diff that maps each (C/A, Unit, Station) location to the total morning riders passing through ALL of the turnstiles in that area.\n",
    "\n",
    "Hint 1: see your work in Exercise 13.\n",
    "\n",
    "Hint 2: ('A002', 'R051','59 ST') should have 2804 morning commuter exits.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "total_morning_diff = {}\n",
    "for key, value in morning_differences.items():\n",
    "    count = 0\n",
    "    for key2, value2 in value.items():\n",
    "        count += value2\n",
    "    total_morning_diff[key] = count\n",
    "print(total_morning_diff[('A002', 'R051', '59 ST')])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "22.Create a list of sorted tuples to see the most popular morning exits.\n",
    "\n",
    "Hint:  ('R238', 'R046', 'GRD CNTRL-42 ST') should be the highest with 17,300 morning exits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "list_of_tuples = []\n",
    "for key, value in total_morning_diff.items():\n",
    "    list_of_tuples.append((value, key))\n",
    "list_of_tuples.sort(reverse=True)\n",
    "print(list_of_tuples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "23.We notice that the ('R204', 'R043', 'WALL ST') stop is pretty high on the Monday morning list. How can we tell if this exit is more of a commuter or tourist exit? Maybe we'll see if the total number of people is higher on a weekday than a weekend. Go back to the original df dataframe. Save only the items that contain ('R204', 'R043', 'WALL ST') to a dataframe called wallstreet and create a list of tuples where the first entry is the date and the second entry is the total ridership. \n",
    "\n",
    "Hint: there should be 9936 riders on 06/15/2017."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "wallstreet = MTA[(MTA['C/A'] == 'R204') \n",
    "                & (MTA['UNIT'] == 'R043')\n",
    "                & (MTA['STATION'] == 'WALL ST')]\n",
    "wallstreet = wallstreet.reset_index(drop=True)\n",
    "\n",
    "wall_dict={}\n",
    "for i in range(len(wallstreet.index)):\n",
    "    mytuple = wallstreet.DATE[i]\n",
    "    if mytuple not in wall_dict.keys():\n",
    "        wall_dict[mytuple]={wallstreet.SCP[i]:{wallstreet.TIME[i]:wallstreet.EXITS[i]}}\n",
    "    if wallstreet.SCP[i] not in wall_dict[mytuple].keys():\n",
    "         wall_dict[mytuple][wallstreet.SCP[i]]={wallstreet.TIME[i]:wallstreet.EXITS[i]}\n",
    "    else:\n",
    "        wall_dict[mytuple][wallstreet.SCP[i]][wallstreet.TIME[i]]=wallstreet.EXITS[i]\n",
    "#print(wall_dict['06/12/2017'])\n",
    "\n",
    "wall_exits = {}\n",
    "for date,turnstile_info in wall_dict.items():\n",
    "    for turnstile,exit_info in turnstile_info.items():\n",
    "        start = wall_dict[date][turnstile][sorted(exit_info)[0]]\n",
    "        end = wall_dict[date][turnstile][sorted(exit_info)[-1]]\n",
    "        if date not in wall_exits.keys():\n",
    "            wall_exits[date]={}\n",
    "        wall_exits[date][turnstile]=end-start\n",
    "print(wall_dict['06/12/2017'])\n",
    "\n",
    "tuple_list = []\n",
    "for date, turnstiles in wall_exits.items():\n",
    "    count = 0 \n",
    "    for exit in turnstiles.values():\n",
    "        count = count + exit\n",
    "    tuple_list.append((date, count))\n",
    "tuple_list.sort()\n",
    "tuple_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "24.Plot the list of tuples you made where date is the x-axis and ridership is the y-axis for this wall street station.\n",
    "\n",
    "Hint: you'll first need to use datetime to convert the dates to datetime format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(tuple_list)\n",
    "%matplotlib inline\n",
    "from datetime import datetime\n",
    "riders = []\n",
    "dates = []\n",
    "for date,rider in tuple_list:\n",
    "    dates.append(datetime.strptime(date,'%m/%d/%Y'))\n",
    "    riders.append(rider)\n",
    "plt.plot(dates,riders, '.');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "25.Now use datetime to convert the dates to \"Mon\", \"Tues\", etc and print the days of the week with corresponding ridership. Is this a commuter stop or a tourist stop?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "for date,rider in tuple_list:\n",
    "    time_info = datetime.strptime(date,'%m/%d/%Y')\n",
    "    print (time_info.strftime(\"%a\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weekday_morning = MTA[MTA]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
